{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74eb8f43-d242-439b-985e-963fbe3c0ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as skTfidf\n",
    "import cupy as cp           #use cupy array instead of numpy to speed up calculation by using GPU\n",
    "import cudf as cf\n",
    "from cuml.metrics.pairwise_distances import sparse_pairwise_distances\n",
    "from cuml.feature_extraction.text import TfidfVectorizer as cuTfidf\n",
    "from cuml.metrics.pairwise_distances import pairwise_distances\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606663a1-fb8b-4fb6-aa3f-978429bf347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './corpus_short_125_no_dup_with_type.csv'\n",
    "def load_frame(path_to_df=path, encoding='utf-16', filter_value = 100000):\n",
    "    \n",
    "    df= pd.read_csv(path_to_df, encoding=encoding, index_col='id')\n",
    "    df.drop([df.columns[0]], inplace=True, axis=1)\n",
    "    df.drop_duplicates(subset=['text'],inplace=True)\n",
    "    \n",
    "    exam_type_distribution = df.groupby(['exam_type'])['exam_type'].count()\n",
    "    exam_type_distribution.sort_values(ascending=False)\n",
    "    \n",
    "    list_filtered = exam_type_distribution[exam_type_distribution > filter_value].index\n",
    "    df_filtered = df[df['exam_type'].isin(list_filtered)]\n",
    "    \n",
    "    print(f'original dataframe shape: {df.shape}')\n",
    "    print(f'df_filtered shape: {df_filtered.shape}')\n",
    "    \n",
    "    print(f'numbers of exam types before: {len(set(df[\"exam_type\"]))}')\n",
    "    print(f'types after filtering: {list_filtered}')\n",
    "    print(f'number of exam types after filtering: {len(set(df_filtered[\"exam_type\"]))}')\n",
    "\n",
    "    return df_filtered, list_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70af3ac-981d-42ca-a71e-abd9f9cd9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a load function to load each exam type\n",
    "def load_exam_type(df, exam_types):\n",
    "    for i in exam_types:\n",
    "        print(f'exam type: {i}')\n",
    "        dataframe = df[df['exam_type'] == i]    \n",
    "        print(f'number of documents: {dataframe.shape}')\n",
    "        yield dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ed5f7f8-51dd-4c43-9169-2135ee9f693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to list all entries with the its similarity inside a threshhold\n",
    "def get_matches(upperbound, lowerbound, batch_size=12000, filter=100000):\n",
    "    # create a dictionary to store the results\n",
    "    results_dict = {}\n",
    "\n",
    "    # start with loading the dataframe\n",
    "    df_filtered = load_frame(filter_value = filter)\n",
    "    df_by_type = load_exam_type(df_filtered[0], df_filtered[1])\n",
    "\n",
    "    # loop over all exam types\n",
    "    for i in range(0,len(df_filtered[1])):\n",
    "        dataframe = next(df_by_type)\n",
    "        #print(f'exam type: {dataframe[\"exam_type\"].iloc[0]}')\n",
    "        for idx, batch in enumerate(range(0, len(dataframe), batch_size)):\n",
    "            batch_info = f'batch number {idx}, rows {batch}:{batch + batch_size}'\n",
    "            # print(batch_info)\n",
    "            # transform the batchch+batch_size].index[i],\n",
    "            # create a tfIdf vectorizer and fit and transform the documents\n",
    "            batch_dataframe = dataframe.iloc[batch:batch + batch_size]\n",
    "            df_indices = batch_dataframe.index.to_list()\n",
    "            tfidf_batch = cuTfidf().fit_transform(batch_dataframe['text'])\n",
    "            # print(f'tfidf shape:{tfidf_batch.shape}')\n",
    "\n",
    "            # calculate the euclidean distance\n",
    "            distances_batch = sparse_pairwise_distances(tfidf_batch, metric='euclidean')\n",
    "\n",
    "            results = euclidean_distance(distances_batch, batch_dataframe, upperbound=upperbound, lowerbound=lowerbound, indices=df_indices)\n",
    "            if results:\n",
    "                results_dict.update(results)\n",
    "            #break\n",
    "        #break\n",
    "    return results_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c585ad4-b5de-44ec-b62d-6b85afe7dd55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to calculate the euclidean distance of a batch of documents \n",
    "# and return the neighbours based on the threshold\n",
    "def euclidean_distance(distance_batch, batch_dataframe, upperbound, lowerbound, indices):\n",
    "\n",
    "    results = {}\n",
    "    distance_batch = distance_batch[0:50] #for sampling/testing purposes\n",
    "    \n",
    "    for i, row in enumerate(distance_batch):\n",
    "\n",
    "        arg_sorted = cp.argsort(row)\n",
    "        sorted_array = row[arg_sorted]\n",
    "        \n",
    "        candidates = get_candidates(sorted_array, arg_sorted, upper=upperbound)\n",
    "                \n",
    "        df_candidates = [indices[int(i)] for i in candidates[1:]]\n",
    "        original_index = indices[i]\n",
    "        distances = sorted_array[1:len(df_candidates)+1]\n",
    "        \n",
    "        if df_candidates:\n",
    "            results[original_index] = (df_candidates, distances)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a1df950a-bbbe-485f-a4d6-1fa04b80446a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_candidates(sorted_array, arg_sorted, upper):\n",
    "    candidates = []\n",
    "    for i, x in enumerate(sorted_array):\n",
    "        if x > upper:\n",
    "            break\n",
    "        else:\n",
    "            candidates.append(int(arg_sorted[i]))\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "14b4e6da-bdda-48ad-a44f-824af88c5c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataframe shape: (2586631, 4)\n",
      "df_filtered shape: (1149916, 4)\n",
      "numbers of exam types before: 985\n",
      "types after filtering: Index(['ARCK', 'ARRT', 'ARRTRBS', 'ARSB'], dtype='object', name='exam_type')\n",
      "number of exam types after filtering: 4\n",
      "exam type: ARCK\n",
      "number of documents: (100888, 4)\n",
      "exam type: ARRT\n",
      "number of documents: (474268, 4)\n",
      "exam type: ARRTRBS\n",
      "number of documents: (449008, 4)\n",
      "exam type: ARSB\n",
      "number of documents: (125752, 4)\n"
     ]
    }
   ],
   "source": [
    "test = get_matches(upperbound=0.2, lowerbound=0, batch_size=12000, filter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f4abb12-9ddb-491a-aaef-22c28724d177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{699394: ([709879], array([0.17644596], dtype=float32)),\n",
       " 921246: ([944357, 975710, 1026933],\n",
       "  array([0.        , 0.        , 0.12366536], dtype=float32)),\n",
       " 2951520: ([2951641], array([0.18948333], dtype=float32)),\n",
       " 2951641: ([2951520], array([0.18948396], dtype=float32)),\n",
       " 3127460: ([3191707], array([0.12182446], dtype=float32)),\n",
       " 1290517: ([1378183, 1585015, 1596270],\n",
       "  array([0.18931559, 0.18931559, 0.19431968], dtype=float32)),\n",
       " 2135117: ([2135162, 2234454], array([0., 0.], dtype=float32)),\n",
       " 2135162: ([2135162, 2234454], array([0., 0.], dtype=float32)),\n",
       " 2135242: ([2147647], array([0.], dtype=float32)),\n",
       " 2567179: ([2773351], array([0.], dtype=float32)),\n",
       " 3431773: ([3546338], array([0.16418344], dtype=float32))}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8f75c694-512b-4af8-b13d-b851c5dffd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataframe shape: (2586631, 4)\n",
      "df_filtered shape: (1149916, 4)\n",
      "numbers of exam types before: 985\n",
      "types after filtering: Index(['ARCK', 'ARRT', 'ARRTRBS', 'ARSB'], dtype='object', name='exam_type')\n",
      "number of exam types after filtering: 4\n"
     ]
    }
   ],
   "source": [
    "df = load_frame()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6d6e28ae-19ab-4732-b8b2-a1da941a42f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sonographie gesamtes Abdomen vom   Klinik Fragestellung Rechtfertigende Indikation  Schockraummanagement Verkehrsunfall FAST   Befund und Beurteilung   Sonographisch kein Nachweis einer Verletzung der parenchymatösen Abdominalorgane  Keine freie intraabdominelle Flüssigkeit abzugrenzen  Soweit einsehbar basal kein wesentlicher Pleura oder Perikarderguss  Harnblase gut gefüllt echofreies Binnenmuster  \n"
     ]
    }
   ],
   "source": [
    "print(df.loc[2135117]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cf285aab-3779-4147-a071-55c56575a490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sonographie gesamtes Abdomen vom   Klinik Fragestellung Rechtfertigende Indikation  Verkehrsunfall Schockraummanagement FAST   Befund und Beurteilung   Sonographisch kein Nachweis einer Verletzung der parenchymatösen Abdominalorgane  Keine freie intraabdominelle Flüssigkeit abzugrenzen  Soweit einsehbar basal kein wesentlicher Pleura oder Perikarderguss  Harnblase gut gefüllt echofreies Binnenmuster '"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[2135162]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fbfef05-b894-4d0b-96d7-67a44f49b22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted_items = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "89975d01-378f-4bbb-982a-85ae67297823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i[0] 699394\n",
      "i[1] ([709879], array([0.17644596], dtype=float32))\n",
      "i[0] 921246\n",
      "i[1] ([944357, 975710, 1026933], array([0.        , 0.        , 0.12366536], dtype=float32))\n",
      "i[0] 2951520\n",
      "i[1] ([2951641], array([0.18948333], dtype=float32))\n",
      "i[0] 2951641\n",
      "i[1] ([2951520], array([0.18948396], dtype=float32))\n",
      "i[0] 3127460\n",
      "i[1] ([3191707], array([0.12182446], dtype=float32))\n",
      "i[0] 1290517\n",
      "i[1] ([1378183, 1585015, 1596270], array([0.18931559, 0.18931559, 0.19431968], dtype=float32))\n",
      "i[0] 2135117\n",
      "i[1] ([2135162, 2234454], array([0., 0.], dtype=float32))\n",
      "i[0] 2135162\n",
      "i[1] ([2135162, 2234454], array([0., 0.], dtype=float32))\n",
      "i[0] 2135242\n",
      "i[1] ([2147647], array([0.], dtype=float32))\n",
      "i[0] 2567179\n",
      "i[1] ([2773351], array([0.], dtype=float32))\n",
      "i[0] 3431773\n",
      "i[1] ([3546338], array([0.16418344], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "for i in test.items():\n",
    "    print(f'i[0] {i[0]}')\n",
    "    print(f'i[1] {i[1]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14e6a7e8-4931-4c21-8c24-b7d472dd9a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699394 [709879]\n",
      "deleted item: [709879]\n",
      "True\n",
      "921246 [944357, 975710, 1026933]\n",
      "deleted item: [709879, 699394, 944357]\n",
      "deleted item: [709879, 699394, 944357, 975710]\n",
      "deleted item: [709879, 699394, 944357, 975710, 1026933]\n",
      "True\n",
      "2951520 [2951641]\n",
      "deleted item: [709879, 699394, 944357, 975710, 1026933, 921246, 2951641]\n",
      "True\n",
      "2951641 []\n",
      "3127460 [3191707]\n",
      "deleted item: [709879, 699394, 944357, 975710, 1026933, 921246, 2951641, 2951520, 3191707]\n",
      "True\n",
      "1290517 [1378183, 1585015, 1596270]\n",
      "deleted item: [709879, 699394, 944357, 975710, 1026933, 921246, 2951641, 2951520, 3191707, 3127460, 1378183]\n",
      "deleted item: [709879, 699394, 944357, 975710, 1026933, 921246, 2951641, 2951520, 3191707, 3127460, 1378183, 1585015]\n",
      "deleted item: [709879, 699394, 944357, 975710, 1026933, 921246, 2951641, 2951520, 3191707, 3127460, 1378183, 1585015, 1596270]\n",
      "True\n",
      "2135117 [2135162, 2234454]\n",
      "deleted item: [709879, 699394, 944357, 975710, 1026933, 921246, 2951641, 2951520, 3191707, 3127460, 1378183, 1585015, 1596270, 1290517, 2135162]\n",
      "deleted item: [709879, 699394, 944357, 975710, 1026933, 921246, 2951641, 2951520, 3191707, 3127460, 1378183, 1585015, 1596270, 1290517, 2135162, 2234454]\n",
      "True\n",
      "2135162 []\n",
      "2135242 [2147647]\n",
      "deleted item: [709879, 699394, 944357, 975710, 1026933, 921246, 2951641, 2951520, 3191707, 3127460, 1378183, 1585015, 1596270, 1290517, 2135162, 2234454, 2135117, 2147647]\n",
      "True\n",
      "2567179 [2773351]\n",
      "deleted item: [709879, 699394, 944357, 975710, 1026933, 921246, 2951641, 2951520, 3191707, 3127460, 1378183, 1585015, 1596270, 1290517, 2135162, 2234454, 2135117, 2147647, 2135242, 2773351]\n",
      "True\n",
      "3431773 [3546338]\n",
      "deleted item: [709879, 699394, 944357, 975710, 1026933, 921246, 2951641, 2951520, 3191707, 3127460, 1378183, 1585015, 1596270, 1290517, 2135162, 2234454, 2135117, 2147647, 2135242, 2773351, 2567179, 3546338]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i, j in test.items():\n",
    "    items_to_delete = [i for i in j[0] if i not in deleted_items]\n",
    "    print(i, items_to_delete)\n",
    "    for ij in items_to_delete:\n",
    "        deleted_items.append(ij)\n",
    "        print(f'deleted item: {deleted_items}')\n",
    "    if i not in deleted_items:\n",
    "        print('True')\n",
    "        df = df.drop([*items_to_delete])\n",
    "        deleted_items.append(i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
