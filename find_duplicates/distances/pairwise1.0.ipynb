{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as skTfidf\n",
    "import cupy as cp           #use cupy array instead of numpy to speed up calculation by using GPU\n",
    "import cudf as cf\n",
    "from cuml.metrics.pairwise_distances import sparse_pairwise_distances\n",
    "from cuml.feature_extraction.text import TfidfVectorizer as cuTfidf\n",
    "from cuml.metrics.pairwise_distances import pairwise_distances\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/test/Data/corpus.csv'\n",
    "path = './corpus.csv'\n",
    "def load_frame(path_to_df=path, encoding='utf-16', filter_value = 100000):\n",
    "    \n",
    "    df= pd.read_csv(path_to_df, encoding=encoding, index_col='id')\n",
    "    df.drop([df.columns[0]], inplace=True, axis=1)\n",
    "    df.drop_duplicates(subset=['text'],inplace=True)\n",
    "    \n",
    "    exam_type_distribution = df.groupby(['exam_type'])['exam_type'].count()\n",
    "    exam_type_distribution.sort_values(ascending=False)\n",
    "    \n",
    "    list_filtered = exam_type_distribution[exam_type_distribution > filter_value].index\n",
    "    df_filtered = df[df['exam_type'].isin(list_filtered)]\n",
    "    \n",
    "    print(f'original dataframe shape: {df.shape}')\n",
    "    print(f'df_filtered shape: {df_filtered.shape}')\n",
    "    \n",
    "    print(f'numbers of exam types before: {len(set(df[\"exam_type\"]))}')\n",
    "    print(f'types after filtering: {list_filtered}')\n",
    "    print(f'number of exam types after filtering: {len(set(df_filtered[\"exam_type\"]))}')\n",
    "\n",
    "    return df_filtered, list_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a load function to load each exam type\n",
    "def load_exam_type(df, exam_types):\n",
    "    for i in exam_types:\n",
    "        print(f'exam type: {i}')\n",
    "        dataframe = df[df['exam_type'] == i]    \n",
    "        print(f'number of documents: {dataframe.shape}')\n",
    "        yield dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_tfidf(sparseMatrix, size = 5000):\n",
    "    for idx, item in enumerate(range(0, sparseMatrix.shape[0], size)):\n",
    "        batch_sparseMatrix = sparseMatrix[item:item+size,:]\n",
    "        print(f'batch shape: {batch_sparseMatrix.shape}, item: {item}')\n",
    "        yield batch_sparseMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(upperbound, batch_size=8000, filter=100000):\n",
    "\n",
    "    df_filtered = load_frame(filter_value = filter)\n",
    "    df_by_type = load_exam_type(df_filtered[0], df_filtered[1])\n",
    "    results_dict = {}\n",
    "\n",
    "    # loop through each exam type\n",
    "    for i in range(0,len(df_filtered[1])):\n",
    "        dataframe = next(df_by_type)\n",
    "        df_indices = dataframe.index.to_list()\n",
    "\n",
    "        tfidf = cuTfidf().fit_transform(dataframe['text'])\n",
    "        \n",
    "        batch = batch_tfidf(tfidf, size=batch_size)\n",
    "        print(f'batches: {math.ceil(tfidf.shape[0]/batch_size)} | batch size: {batch_size}')\n",
    "        \n",
    "        # loop through bathes of tfidf matrix row wise\n",
    "        counter = 0\n",
    "        for i in range(0, math.ceil(tfidf.shape[0]/batch_size)):\n",
    "            # distances = []\n",
    "            batch_sparse = next(batch)\n",
    "            batch_dataframe = dataframe[counter:counter+batch_size]\n",
    "            batch_indices = batch_dataframe.index.to_list() # no batch indices needed if using candidates[0]\n",
    "                                                            # see below in sort_by_distance for \n",
    "            \n",
    "            distance_batch = sparse_pairwise_distances(batch_sparse, tfidf, metric='euclidean')\n",
    "            \n",
    "            candidates_and_distances = sort_by_distance(distance_batch, df_indices, batch_indices, upperbound, results)\n",
    "            \n",
    "            if candidates_and_distances:\n",
    "                results_dict.update(candidates_and_distances)\n",
    "            \n",
    "            counter += batch_size\n",
    "\n",
    "            del distance_batch\n",
    "            del batch_sparse\n",
    "\n",
    "        del tfidf\n",
    "        del batch\n",
    "        return candidates_and_distances\n",
    "        break\n",
    "                \n",
    "    return candidates_and_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sort_by_distance(distance_batch, df_indices, upperbound, results):\n",
    "    for i, row in enumerate(distance_batch):\n",
    "        sorted_array = np.sort(row)\n",
    "        arg_sorted = np.argsort(row)\n",
    "        # working\n",
    "        # candidates = get_candidates(sorted_array, arg_sorted, upperbound)[1:]\n",
    "        # df_candidates = [df_indices[int(i)] for i in candidates]\n",
    "        # original_index = batch_indices[i]\n",
    "\n",
    "        # new version without batch indices\n",
    "        candidates = get_candidates(sorted_array, arg_sorted, upperbound)\n",
    "        df_candidates = [df_indices[int(i)] for i in candidates[1:]]\n",
    "        original_index = candidates[0]\n",
    "        \n",
    "\n",
    "        if candidates:\n",
    "            # results[original_index] = (df_candidates)\n",
    "\n",
    "            results.update(save_results(sorted_array, candidates, df_candidates, original_index))\n",
    "            \n",
    "    return results\n",
    "\n",
    "# candidates_and_distances = sort_by_distance(distance_batch, dataframe_indices, batch_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(sorted_array, arg_sorted, upper):\n",
    "    candidates = []\n",
    "    for i, x in enumerate(sorted_array):\n",
    "        if x > upper:\n",
    "            break\n",
    "        else:\n",
    "            candidates.append(int(arg_sorted[i]))\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(sorted_array, candidates, df_candidates, original_index):\n",
    "    results = {}\n",
    "    distances = sorted_array[1:len(candidates)+1]\n",
    "    results[original_index] = (df_candidates, distances)\n",
    "    return results\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataframe shape: (2586631, 4)\n",
      "df_filtered shape: (1149916, 4)\n",
      "numbers of exam types before: 985\n",
      "types after filtering: Index(['ARCK', 'ARRT', 'ARRTRBS', 'ARSB'], dtype='object', name='exam_type')\n",
      "number of exam types after filtering: 4\n",
      "exam type: ARCK\n",
      "number of documents: (100888, 4)\n",
      "batches: 13 - batch size: 8000\n",
      "(8000, 66772) 0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'cupy._core.core.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mget_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupperbound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [5], line 28\u001b[0m, in \u001b[0;36mget_distances\u001b[0;34m(upperbound, batch_size, filter)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# batch_dataframe = dataframe[counter:counter+batch_size]\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# batch_indices = batch_dataframe.index.to_list() # no batch indices needed if using candidates[0]\u001b[39;00m\n\u001b[1;32m     24\u001b[0m                                                 \u001b[38;5;66;03m# see below in sort_by_distance for \u001b[39;00m\n\u001b[1;32m     26\u001b[0m distance_batch \u001b[38;5;241m=\u001b[39m sparse_pairwise_distances(batch_sparse, tfidf, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m candidates_and_distances \u001b[38;5;241m=\u001b[39m \u001b[43msort_by_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistance_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupperbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m distance_batch\n",
      "Cell \u001b[0;32mIn [6], line 20\u001b[0m, in \u001b[0;36msort_by_distance\u001b[0;34m(distance_batch, df_indices, upperbound, results)\u001b[0m\n\u001b[1;32m     18\u001b[0m             distances \u001b[38;5;241m=\u001b[39m sorted_array[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;28mlen\u001b[39m(df_candidates)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     19\u001b[0m             results[original_index] \u001b[38;5;241m=\u001b[39m (df_candidates, distances)\n\u001b[0;32m---> 20\u001b[0m         \u001b[43msave_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43msorted_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_candidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "Cell \u001b[0;32mIn [6], line 19\u001b[0m, in \u001b[0;36msort_by_distance.<locals>.save_results\u001b[0;34m(sorted_array, df_candidates, results)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_results\u001b[39m(sorted_array, df_candidates, results): \n\u001b[1;32m     18\u001b[0m     distances \u001b[38;5;241m=\u001b[39m sorted_array[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;28mlen\u001b[39m(df_candidates)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43moriginal_index\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m (df_candidates, distances)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'cupy._core.core.ndarray'"
     ]
    }
   ],
   "source": [
    "test = get_distances(upperbound=0.5, batch_size=8000, filter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataframe shape: (2586631, 4)\n",
      "df_filtered shape: (1149916, 4)\n",
      "numbers of exam types before: 985\n",
      "types after filtering: Index(['ARCK', 'ARRT', 'ARRTRBS', 'ARSB'], dtype='object', name='exam_type')\n",
      "number of exam types after filtering: 4\n",
      "exam type: ARCK\n",
      "number of documents: (100888, 4)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "loaded = load_frame()\n",
    "exam_types = loaded[1]\n",
    "df = loaded[0]\n",
    "df_by_type = load_exam_type(df, exam_types)\n",
    "dataframe = next(df_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 66772) 0\n",
      "batches: 13 | batch size: 8000\n",
      "tfidf shape: (100888, 66772)\n",
      "sparse pairse distance batch shape: (50, 100888)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# calcuate tfidf and batch the sparse matrix\n",
    "tfidf = cuTfidf().fit_transform(dataframe['text'])\n",
    "batch_size = 8000\n",
    "batch = batch_tfidf(tfidf, size = batch_size)\n",
    "batch_sparse = next(batch)\n",
    "print(f'batches: {math.ceil(tfidf.shape[0]/batch_size)} | batch size: {batch_size}')\n",
    "\n",
    "dataframe_indices = dataframe.index.to_list()\n",
    "print(f'tfidf shape: {tfidf.shape}')\n",
    "\n",
    "distance_batch = sparse_pairwise_distances(batch_sparse, tfidf, metric='euclidean') # distance matrix\n",
    "distance_batch.shape # distance_batch takes 2 gigabytes of memory, needs to be deleted after use\n",
    "\n",
    "distance_batch = distance_batch[0:50] #take a small sample of the distance matrix\n",
    "print(f'sparse pairse distance batch shape: {distance_batch.shape}')\n",
    "results={} # to save the results as a dictionary\n",
    "upperbound = 0.5  # upperbound of the distance to be considered as a match\n",
    "\n",
    "for i, row in enumerate(distance_batch):\n",
    "    arg_sorted  = np.argsort(row)\n",
    "    sorted_array = np.sort(row)\n",
    "    # print(arg_sorted)\n",
    "    # print(sorted_array)\n",
    "\n",
    "    candidates = get_candidates(sorted_array, arg_sorted, upperbound) # get the candidates\n",
    "    if len(candidates) > 1:\n",
    "    \n",
    "        df_candidates = [dataframe_indices[i] for i in candidates]\n",
    "        original_index = df_candidates[0]\n",
    "        df_candidates = df_candidates[1:]\n",
    "        # if df_candidates:\n",
    "        #     print(f'df_candidates: {df_candidates}')\n",
    "        #     print(f'# of df candidates: {len(df_candidates)}')\n",
    "\n",
    "        # original_index = batch_indices[i]\n",
    "        # print(original_index)\n",
    "\n",
    "        distances = sorted_array[1:len(candidates)+1]\n",
    "        results[original_index] = (df_candidates, distances)\n",
    "        \n",
    "del distance_batch\n",
    "del tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of candidates: 281\n",
      "\n",
      "original text:\n",
      "CT Kopf vom    Klinik Fragestellung Rechtfertigende Indikation  Kopfschmerzen   Methodik  Digitale Übersichtsradiographien Parallel zur OrbitoMeatalLinie gewinkelte native ZeilenCT des Kopfes in  mm Schichtdicke Bildschirmbefundung  Befund Es liegen keine Voraufnahmen zum Vergleich vor  Kein Nachweis einer frischen intrakraniellen Blutung Kein Nachweis eines demarkierten frischen zerebralen Infarkts Mittelständiger Interhemisphärenspalt Normal weites symmetrisches Ventrikelsystem ohne Anhalt für einen Liquoraufstau Basale Zisternen und  Ventrikel frei einsehbar Keine Hirndruckzeichen Kein Nachweis einer Raumforderung soweit nativ beurteilbar Keine pathologischen Veränderungen der Schädelkalotte und Schädelbasis Regelrechte Anlage und freie Pneumatisation der mit abgebildeten NNH und der Mastoidzellen  Beurteilung  Kein Nachweis einer ICB     \n",
      "\n",
      "Vergleichstext mit distance: 0.21215848624706268 \n",
      "CT Kopf vom    Klinik Fragestellung Rechtfertigende Indikation  Blutung  Methodik  Digitale Übersichtsradiographien Parallel zur OrbitoMeatalLinie gewinkelte native ZeilenCT des Kopfes in  mm Schichtdicke Bildschirmbefundung  Befund Es liegen keine Voraufnahmen zum Vergleich vor  Kein Nachweis einer frischen intrakraniellen Blutung  Kein Nachweis eines demarkierten frischen zerebralen Infarkts  Mittelständiger Interhemisphärenspalt Normal weites symmetrisches Ventrikelsystem ohne Anhalt für einen Liquoraufstau Basale Zisternen und  Ventrikel frei einsehbar Keine Hirndruckzeichen Kein Nachweis einer Raumforderung soweit nativ beurteilbar  Keine pathologischen Veränderungen der Schädelkalotte und Schädelbasis Regelrechte Anlage und freie Pneumatisation der mit abgebildeten NNH und der Mastoidzellen   \n",
      "\n",
      "Vergleichstext mit distance: 0.2518804967403412 \n",
      "CT Kopf vom    Klinik Fragestellung Rechtfertigende Indikation  Zn Kopftrauma ICB Blutung   Methodik  Digitale Übersichtsradiographien Parallel zur OrbitoMeatalLinie gewinkelte native ZeilenCT des Kopfes in  mm Schichtdicke Bildschirmbefundung  Befund Es liegen keine Voraufnahmen zum Vergleich vor  Kein Nachweis einer frischen intrakraniellen Blutung  Kein Nachweis eines demarkierten frischen zerebralen Infarkts  Mittelständiger Interhemisphärenspalt Normal weites symmetrisches Ventrikelsystem ohne Anhalt für einen Liquoraufstau Basale Zisternen und  Ventrikel frei einsehbar Keine Hirndruckzeichen Kein Nachweis einer Raumforderung soweit nativ beurteilbar  Keine pathologischen Veränderungen der Schädelkalotte und Schädelbasis Regelrechte Anlage und freie Pneumatisation der mit abgebildeten NNH und der Mastoidzellen  Beurteilung   Kein Nachweis einer frischen intrakraniellen Blutung   Kein Frakturnachweis  \n",
      "\n",
      "Vergleichstext mit distance: 0.2592889666557312 \n",
      "CT Kopf vom    Klinik Fragestellung Rechtfertigende Indikation  Zn KV Ausschluss Traumafolgen  Methodik  Digitale Übersichtsradiographien Parallel zur OrbitoMeatalLinie gewinkelte native ZeilenCT des Kopfes in  mm Schichtdicke Bildschirmbefundung  Befund Es liegen keine Voraufnahmen zum Vergleich vor  Kein Nachweis einer frischen intrakraniellen Blutung Kein Nachweis eines demarkierten frischen zerebralen Infarkts Mittelständiger Interhemisphärenspalt Normal weites symmetrisches Ventrikelsystem ohne Anhalt für einen Liquoraufstau Basale Zisternen und  Ventrikel frei einsehbar Keine Hirndruckzeichen Kein Nachweis einer Raumforderung soweit nativ beurteilbar Keine pathologischen Veränderungen der Schädelkalotte und Schädelbasis Regelrechte Anlage und freie Pneumatisation der mit abgebildeten NNH und der Mastoidzellen  Beurteilung  Kein Nachweis einer intrakraniellen Blutung  Kein Nachweis von Frakturen  \n",
      "\n",
      "Vergleichstext mit distance: 0.26110345125198364 \n",
      "CT Neurocranium vom    Klinik  Anhalt für RF SAB Hirndruckzeichen  Methodik  Digitale Übersichtsradiographien Parallel zur OrbitoMeatalLinie gewinkelte native ZeilenCT des Kopfes in  mm Schichtdicke Bildschirmbefundung  Befund Es liegen keine Voraufnahmen zum Vergleich vor  Kein Nachweis einer frischen intrakraniellen Blutung  Kein Nachweis eines demarkierten frischen zerebralen Infarkts  Mittelständiger Interhemisphärenspalt Normal weites symmetrisches Ventrikelsystem ohne Anhalt für einen Liquoraufstau Basale Zisternen und  Ventrikel frei einsehbar Keine Hirndruckzeichen Kein Nachweis einer Raumforderung soweit nativ beurteilbar  Keine pathologischen Veränderungen der Schädelkalotte und Schädelbasis Regelrechte Anlage und freie Pneumatisation der mit abgebildeten NNH und der Mastoidzellen  Beurteilung Unauffälliges kraniales CT   \n",
      "\n",
      "Vergleichstext mit distance: 0.2612157464027405 \n",
      "CT Neurocranium vom   Klinik Fragestellung Rechtfertigende Indikation  Kopfschmerzen  Methodik  Digitale Übersichtsradiographien Parallel zur OrbitoMeatalLinie gewinkelte native ZeilenCT des Kopfes in  mm Schichtdicke Bildschirmbefundung  Befund Es liegen keine Voraufnahmen zum Vergleich vor  Kein Nachweis einer frischen intrakraniellen Blutung  Kein Nachweis eines demarkierten frischen territorialen Infarkts  Mittelständiger Interhemisphärenspalt Normal weites symmetrisches Ventrikelsystem ohne Anhalt für einen Liquoraufstau Basale Zisternen und  Ventrikel frei einsehbar Keine Hirndruckzeichen Kein Nachweis einer Raumforderung soweit nativ beurteilbar  Diskrete Stammganglienverkalkung rechts Keine pathologischen Veränderungen der Schädelkalotte und Schädelbasis Regelrechte Anlage und freie Pneumatisation der mit abgebildeten NNH und der Mastoidzellen  Beurteilung Kein Nachweis einer frischen intrakraniellen Blutung Kein Nachweis eines demarkierten frischen territorialen Infarkts    \n",
      "\n",
      "Vergleichstext mit distance: 0.2613845467567444 \n",
      "CT Neurocranium vom   Klinik  Zunehmende Kopfschmerzen ICB SAB  Methodik  Digitale Übersichtsradiographien Parallel zur OrbitoMeatalLinie gewinkelte native ZeilenCT des Kopfes in  mm Schichtdicke Bildschirmbefundung  Befund Es liegen keine Voraufnahmen zum Vergleich vor  Kein Nachweis einer frischen intrakraniellen Blutung  Kein Nachweis eines demarkierten frischen zerebralen Infarkts  Mittelständiger Interhemisphärenspalt Normal weites symmetrisches Ventrikelsystem ohne Anhalt für einen Liquoraufstau Basale Zisternen und  Ventrikel frei einsehbar Keine Hirndruckzeichen Kein Nachweis einer Raumforderung soweit nativ beurteilbar  Keine pathologischen Veränderungen der Schädelkalotte und Schädelbasis Regelrechte Anlage und freie Pneumatisation der mit abgebildeten NNH und der Mastoidzellen Kleine Falxverkalkungen parietal  Beurteilung Unauffälliges kraniales CT  \n",
      "\n",
      "# of candidates: 1\n",
      "\n",
      "original text:\n",
      "CT Kopf vom  CT Gesichtsschädel vom   Klinik Fragestellung rechtfertigende Indikation Zn Sturz Blutung Fraktur  Methodik Digitale Übersichtsradiographien Parallel zur OrbitoMeatalLinie gewinkelte InkrementalCCT sowie SpiralCT des Gesichtsschädels nativ in  mm Schichtdicke MPR  Befund  Beurteilung Es liegen keine Voraufnahmen zum Vergleich vor   Kein Nachweis einer frischen intrakraniellen Blutung   Kein Nachweis eines demarkierten frischen Territorialinfarkts   Mittelständiger Interhemisphärenspalt Symmetrisches Ventrikelsystem ohne Anhalt für einen Liquoraufstau Basale Zisternen und  Ventrikel frei einsehbar   Kein Frakturnachweis im Bereich der Kalotte der Schädelbasis des Gesichtsschädels und der miterfassten HWS  Schleimhautschwellung Sinus maxillaris rechts Kleiner Polyp Sinus sphenoidalis links  Darüber hinaus NNH und Mastoidzellen frei pneumatisiert \n",
      "\n",
      "Vergleichstext mit distance: 0.42738425731658936 \n",
      "CT Kopf vom  CT Gesichtsschädel vom   Klinik Fragestellung Rechtfertigende Indikation  Zn Sturz Fraktur Blutung  Methodik Digitale Übersichtsradiographien Parallel zur OrbitoMeatalLinie gewinkelte InkrementalCCT sowie SpiralCT des Gesichtsschädels nativ in  mm Schichtdicke MPR  BefundBeurteilung Es liegen keine Voraufnahmen zum Vergleich vor   Kein Frakturnachweis im Bereich der Kalotte des Gesichtsschädels und der miterfassten HWS  Kein Nachweis einer frischen intrakraniellen Blutung   Kein Nachweis eines demarkierten frischen Territorialinfarkts   Mittelständiger Interhemisphärenspalt Symmetrisches Ventrikelsystem ohne Anhalt für einen Liquoraufstau Basale Zisternen und  Ventrikel frei einsehbar  Schleimhautschwellung Sinus maxillaris bds Darüber hinaus NNH und Mastoidzellen frei pneumatisiert  \n",
      "\n",
      "# of candidates: 1\n",
      "\n",
      "original text:\n",
      "CT Kopf vom   Klinik Fragestellung Rechtfertigende Indikation  Zn Sturz Fraktur Blutung  Methodik  Digitale Übersichtsradiographien Parallel zur OrbitoMeatalLinie gewinkelte native MSCT des Kopfes MPR  Befund Es liegen die Voraufnahmen vom  zum Vergleich vor Kein Nachweis einer frischen intrakraniellen Blutung Kein Nachweis eines demarkierten zerebralen Territorialinfarkts Keine Frühinfarktzeichen im nativen CCT Mittelständiger Interhemisphärenspalt Normal weites symmetrisches Ventrikelsystem ohne Anhalt für einen Liquoraufstau Basale Zisternen und  Ventrikel frei einsehbar Keine Hirndruckzeichen Kein Nachweis einer Raumforderung soweit nativ beurteilbar Kein Nachweis einer frischen Fraktur Freie Pneumatisation der mit abgebildeten NNH und der Mastoidzellen  Beurteilung Es liegen die Voraufnahmen vom  zum Vergleich vor  Kein Nachweis einer frischen intrakraniellen Blutung  Kein Nachweis einer frischen Fraktur  \n",
      "\n",
      "Vergleichstext mit distance: 0.4584881067276001 \n",
      "CT Kopf vom   Klinik Fragestellung Rechtfertigende Indikation  Zn KV ICB SAB Fraktur  Methodik  Digitale Übersichtsradiographien Parallel zur OrbitoMeatalLinie gewinkelte native ZeilenCT des Kopfes MPR  Befund Es liegen die Voraufnahmen vom  zum Vergleich vor Kein Nachweis einer frischen intrakraniellen Blutung Kein Nachweis eines demarkierten zerebralen Territorialinfarkts  Mittelständiger Interhemisphärenspalt Normal weites symmetrisches Ventrikelsystem ohne Anhalt für einen Liquoraufstau Basale Zisternen und  Ventrikel frei einsehbar Keine Hirndruckzeichen Kein Nachweis einer Raumforderung soweit nativ beurteilbar Kein Nachweis einer frischen Fraktur Regelrechte Anlage und freie Pneumatisation der mit abgebildeten NNH und der Mastoidzellen  Beurteilung Es liegen die Voraufnahmen vom  zum Vergleich vor  Kein Nachweis einer frischen intrakraniellen Blutung  Kein Nachweis einer frischen Fraktur \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(results) to show the examples of results with distances\n",
    "\n",
    "for i, j in results.items():\n",
    "\n",
    "    # loop through every 10th item in j[0]\n",
    "    print(f'# of candidates: {len(j[0])}\\n')\n",
    "    original_text = dataframe.loc[i]['text']\n",
    "    print(f'original text:\\n{original_text}')\n",
    "    for i, k in enumerate(j[0][::50]):\n",
    "        \n",
    "        text = dataframe.loc[k]['text']\n",
    "        \n",
    "        print(f'\\nVergleichstext mit distance: {j[1][i]} \\n{text}')\n",
    "        \n",
    "        \n",
    "        #print(dataframe.loc[k]['text'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([3961627], array([0.4273842], dtype=float32)), ([3345037], array([0.45848805], dtype=float32))]\n",
      "[954, 1471]\n"
     ]
    }
   ],
   "source": [
    "# select the 2nd item from results dictionary\n",
    "print(list(results.values())[1:])\n",
    "print(list(results)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8000)\n",
      "1675\n",
      "0\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "# calculate by hand row for row is not efficient\n",
    "distances = []\n",
    "for i, j in tqdm(enumerate(batch_sparse)):\n",
    "    x = batch_sparse[i]\n",
    "    distance = sparse_pairwise_distances(x, tfidf, metric='euclidean')[0]\n",
    "    distances.append(distance)\n",
    "    \n",
    "    del x\n",
    "    del distance\n",
    "print(len(distances),len(distances[0]))\n",
    "\n",
    "\n",
    "# calculation when multiplying by 'hand' results in a slightly different result, \n",
    "# but the difference is negligible\n",
    "\n",
    "first=sparse_pairwise_distances(batch_sparse[0], batch_sparse, metric='euclidean')\n",
    "print(first.shape)\n",
    "full = sparse_pairwise_distances(batch_sparse, metric='euclidean')\n",
    "# show the different values between first[0] and full[0,:]\n",
    "# sum the number of different values\n",
    "print(sum(first[0] != full[0,:]))\n",
    "print(sum(abs(first[0] - full[0,:]) > 0.01))\n",
    "print(len(first[0]))\n",
    "\n",
    "# for i in range(len(first[0])):\n",
    "#     if abs(first[0][i] - full[0,i]) > 0.1:\n",
    "#         print(i, first[0][i], full[0,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "936 ns ± 14.4 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "1.73 µs ± 3.27 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
      "2.74 µs ± 5.12 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "2.26 µs ± 12.6 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "42.3 ns ± 0.14 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# different methods for appending each single calculation has different performance with\n",
    "# -> python list being the quickest and numpy array vstack being the slowest\n",
    "# -> use numpy concatenate for the best performance if numpy is required\n",
    "py_array = [[0, 1, 2], [0, 2, 0]]\n",
    "py_row = [4, 5, 6]\n",
    "numpy_array = np.array(py_array)\n",
    "numpy_row = np.array([4,5,6])\n",
    "\n",
    "%timeit np.array(py_array)\n",
    "%timeit np.concatenate([numpy_array, numpy_row.reshape(1, -1)], axis=0)\n",
    "%timeit np.vstack([numpy_array, numpy_row]) \n",
    "%timeit np.append(numpy_array, numpy_row.reshape(1, -1), axis=0)\n",
    "list_array = []\n",
    "%timeit py_array.append(py_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = cuTfidf().fit_transform(dataframe['text'])\n",
    "# deleting the tfidf variable to free up memory space with del tfidf does not work\n",
    "# -> use gc.collect() to free up memory space"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1db4f5d0922d89d25577440296dd50b5676959cd32c2dcd20f446ff62ca4bf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
